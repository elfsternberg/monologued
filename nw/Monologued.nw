% -*- Mode: noweb; noweb-code-mode: rust-mode ; noweb-doc-mode: latex-mode -*-
\documentclass{article}
\usepackage{noweb}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{fontspec, xunicode, xltxtra}
\setmainfont{Centaur MT Std}

\begin{document}

% Generate code and documentation with:
%
% noweave -filter l2h -delay -x -html backbonestore.nw | htmltoc > backbonestore.html
% notangle -Rstore.js backbonestore.nw > store.js
% notangle -Rindex.html backbonestore.nw > index.html

\section{Introduction}

\textbf{Monologued is an RFC-1288 server.}

Monologued is an RFC-1288 (RUIP: Remote User Information Protocol)
server with a restrict (Q1 only) syntax.  It has been mostly written as
an exercise in Rust to learn the MIO (Metal I/O) and libc interfaces, as
well as Rust in general.

RUIP offers two syntaces:

\begin{lstlisting}
{Q1}    ::= [{W}|{W}{S}{U}]{C}
{Q2}    ::= [{W}{S}][{U}]{H}{C}
{U}     ::= username
{H}     ::= @hostname | @hostname{H}
{W}     ::= /W 
{S}     ::= <SP> | <SP>{S}
{C}     ::= <CRLF>
\end{lstlisting}

Monologued supports only the Q1 query, and can be restricted further to
limit the Q1 query only to those users in a defined group, or even to a
list of usernames specified in a file or on the command line.  It
delivers only a user's `.plan` file.  Monologued keeps a small, command
line-limited collection of plans in a cache, to further support
displaying them on request.

In the spirit of traditional IP protocol rules, Monologued is fairly
liberal in its treatment of \{S\} and \{C\}, attempting to make sense of
them.  It's input buffer is limited to 1KB by default; the maximum
output size of a .plan file is 128KB.  Changing these limits would
require a recompile.

\subsection{Literate Program}

A note: this article was written with the
\nwanchorto{http://en.wikipedia.org/wiki/Literate_programming}{Literate
 Programming} toolkit
\nwanchorto{http://www.cs.tufts.edu/~nr/noweb/}{Noweb}. Where you see
something that looks like \texttt{\<\<this\>\>}, it's a placeholder for code
described elsewhere in the document.  Placeholders with an equal sign
at the end of them indicate the place where that code is defined.  The
link (U->) indicates that the code you're seeing is used later in the
document, and (<-U) indicates it was used earlier but is being defined
here.

\subsection{Revision}

This is version 0.4 of \textbf{Monologued}.  

Instructions on generating the code and documentation from this document
are provided in the accompanying Makefile.

\subsection{Organization}

An RUIP server is a fairly straightforward programming exercise.  As
we're using MIO, I expect to be using the [[select/poll]] feature with
which to interact with the outside world, and [[libc]]'s [[getpwnam_r]],
[[getpwent_r]], and [[lstat]] functionality to determine the presence
and availability of the user's [[.plan]] file.

To that end, the basic functionality will be, "For a given username,
return either the plan or a message about discovery failure."  This is
straight-up railway-oriented programming, with more precise failures the
further down into the syntax we go. 

The structure of Monologued is that of a basic server, which parses the
request and either fails or passes the username to the handler; the
username lookup either passes or fails (this is important because if you
delete the username but not the home directory, the inotify feature
fails); if the username lookup passes we request the plan.

The plan lookup is twofold-- if the plan is in the cache, we return it
immediately.  If it isn't, we pull up the plan and, if it's small
enough, cache it.  Either way, we return it to the server to be sent
back out.  If there is no plan, we return an error.  If the plan is new
to the cache, we add it, and we send a message to the server saying that
it needs to add a new path.  (This is a wrapper layer \textit{before}
the cache.)

If Monologued gets a message saying the plan has changed, it evicts the
existing plan.  That is all.  It loads the new plan upon the next
request.

\section{The cache}

The cache is a complicated beast and it took me forever to understand
it.  The basic premise of a cache like this is simple: it's a standard
dictionary, a Rust \texttt{HashMap}, in which every item carries both
its key, its value, and two pointers for a doubly-linked list.  The list
mutates such that recently accessed item is always moved the head.
Every access always involves four six assignments: two to detach the
node from wherever it is, four to re-attach it at the head.

Because RFC-1288 is a text-oriented protocol, the cache is designed to
hold text objects, and to limit the maximum amount of memory used by the
cached text objects.  To that end, the cache's constructor has two
parameters: a maximum object size, and a maximum object count.  The
maximum cache size is the product of these two parameters, but the
actual number of objects in the cache can be much greater than the
maximum object count so long as the total cache size stays below the
maximum.

Objects deposited into this cache must have a ``byte\_size'' method that
dictates how much ``space'' the object takes up.  For our purposes, this
is the number of bytes in our text objects, which approximates memory
usage, but it can be any arbitrary calculation, in which case the
relationship between cache size and memory usage is also arbitrary.

<<Describe The ByteSized Trait>>=
trait ByteSized {
    fn byte_size(&self) -> usize;
}
@

The main object in which we keep our cached item also keeps the key and
the pointers to neighboring objects, if any.  In order to be cacheable,
the key must meet the traits of [[Hash]] and [[PartialEq]], and our
value must be ByteSized.  The pointers are just pointers.  Rust's type
declarations are a bit wonky, but I'm getting used to them.

<<Define The LRU Cache Item>>=
struct LruCacheItem<K: Hash + PartialEq, V: ByteSized> {
    key: K,
    value: V,
    prev: *mut LruCacheItem<K, V>,
    next: *mut LruCacheItem<K, V>
};
@

And since we're doing text, i.e. strings, we can define that now:

<<Make Strings ByteSized>>=
impl ByteSized for String {
    fn byte_size(&self) -> usize {
        self.len()
    }
}
@

[[HashMap]] takes a key and a value, but we've put the key into the item
that will be the [[HashMap]] value.  That's okay; what [[HashMap]]
really needs is anything with the [[Hash]] trait that it can call to
figure out into which bucket to put the value.  We can make an object
that references the item and provides the hash of the key.  First, we'll
need the reference:

<<A Reference to the Cache Key>>=
struct LruKeyRef<K> {
    k: *const K
}
@

And an implementation.  Dereferencing a raw pointer is always unsafe
since there are no guarantees it refers to a valid object at compile
time, so it needs to be marked as such.

<<Implement Hash For The Key>>=
impl<K: Hash> Hash for LruKeyRef<K> {
    fn hash<H: Hasher>(&self, state: &mut H) {
        unsafe { (*self.k).hash(state) }
    }
}
@

The other thing we need is to implement the [[PartialEq]] trait for our
hash key.  Again, there are no compile-time assurances that the pointer
is valid, so dereferencing the key pointer must be marked unsafe.

For me, the most perplexing thing about this was the signature of the
unsafe statement.  It took me forever to understand it. So let's go
through it.  First, the signature for the PartialEq Trait is:

<<PartialEq>>=
pub trait Eq: PartialEq<Self> { 
    fn eq(&self, other) -> bool
}
@

What are we comparing?  The \texttt{k: *const K} from
\texttt{LruKeyRef}.  So first we need to dereference that in order to
access it.  So that's \texttt{*self.k}.  That's the object whose
equality we will be comparing.  But we don't want to copy it, so we need
a reference to it.  That's why the right hand side of the expression
reads \texttt{&*other.k}.

And why doesn't the left hand side say it's a reference?  Because Self
objects are always automatically made references.  It's a Rust thing.
               
When people talk about how
\nwanchorto{http://www.jsoftware.com/papers/tot.htm}{``Notation is a
  Tool for Thought``}, I often get tripped up by examples like this.  We
are learning a new and separate language here, and in some cases I can
understand how it's helpful, but in others it feels more like a barrier
to learning.

<<Implement PartialEQ for the Key>>=
impl<K: PartialEq> PartialEq for LruKeyRef<K> {
    fn eq(&self, other: &LruKeyRef<K>) -> bool {
        unsafe { (*self.k).eq(&*other.k) }
    }
}

impl<K: Eq> Eq for KeyRef<K> {}
@

Now we're ready to define the structure of the cache itself.  We're
going to move our cache items onto the heap so they can survive the
cache being passed around, manipulated, and so forth, and because it'll
make managing the pointers much less insane.  Here we keep the maximum
size of an item and of the cache, as well as the head and tail
pointers. 

<<The LRUCache>>=
pub struct LruCache<K, V> {
    cache: HashMap<LruKeyRef<K>, Box<LruCacheItem<K, V>>>,
    maxitemsize: usize,
    maxtotalsize: usize,
    cursize: usize,
    head *mut LruCacheItem<K, V>,
    tail *mut LruCacheItem<K, V>
};
@

The implementation for the cache is actually not that complicated.
Here's the basic framework, where we define the implementation for a
cache where the key is hashable and equatable, and the value is
bytesized (which is the only implementation we're going to work with).

<<Methods for the cache>>=
impl<K: Hash + Eq, V: ByteSized> LruCache<K, V> {
    <<Cache Constructor>>

    <<Insert an Item>>

    <<Remove an Item>>

    <<Get an Item>>

    <<Check for Key's Presence>>

    <<Remove an Item>>

    /* Private interface */
    <<Evict Items until there's enough room>>

    <<Detach an item from anywhere in the linked list>>

    <<Attach an item to the head of the list>>

    <<Detach, then Attach, to Re-Prioritize>>
}
@

The constructor is fairly simple, although you'd never guess from the
operation at the end.  We need a new [[HashMap]], the various sizes
we're going to track, and the head and tail of our linked list.  The
head and the tail are pointers to heap objects, LruCacheItem caches,
that themselves contain pointers to [[next]] and [[prev]].  We then
create the classic ``empty list'' ouroboros, handling the initialization
ourselves.

<<Cache Constructor>>=
pub fn new(usize maxcount, usize maxsize) -> LruCache<K, V> {
    let mut lrucache = LruCache {
        cache: Hashmap::new(),
        unitsize: maxsize,
        maxsize: maxsize * maxcount,
        cursize: 0,
.            /* I like how the documentation says "Really, reconsider
           before you do something like this." */
        head: unsafe { Box::into_raw(Box_new(mem::uninitialized::<LruCacheItem<K, V>>())) },
        tail: unsafe { Box::into_raw(Box_new(mem::uninitialized::<LruCacheItem<K, V>>())) }
    }
    
    /* Head now contains a pointer to an unboxed heap object that
       is an LruCacheItem, so that LruCacheItem's 'next' field can
       be addressed and set to the unboxed heap object Tail.  And
       vice versa.
     */
    unsafe {
        (*lrucache.head).next = lrucache.tail;
        (*lrucache.tail).prev = lrucache.head;
    }

    lrucache
}
@


\section{The file finder}

An RUIP program is essentially a weak web server; it serves only one
document, understands only one syntax, and that's about it.  There are
some security issues around serving that document, so we'll address
those in this section.

The document we are looking for is, in Unix terminology,
\texttt{\$HOME/.plan}.

To that end, our goal is to turn a username into a plan file.  We'll
build a module file for that.

<<plan/mod.rs>>=
pub mod path;
pub mod plan;
@

Let's declare a function to lookup the user's path using the username
via libc.  We're going to return either a valid path to the user's home
directory, or we're going to return an error message.  

<<plan/plan.rs>>=
fn get_userpath(username: &str) -> Result<str, &'static str> {
@

The first thing we need is the username as a cstring.

<<plan/plan.rs>>=
    let c_username = match std::ffi::CString::new(username) {
        Ok(s)  => s,
        Err(_) => return Err("Could not convert username?")
    };
@ 

We'll be using the re-entrant version of [[getpwnam]], so we're going to
need a password structure, a buffer to store the null-terminated strings
that [[getpwnam]] returns, and a pointer to the result that [[getpwnam]]
uses as an error handling condition, which ends up either pointing to
the password structure, or NULL if it fails.  Which is, admittedly,
kinda silly, but it's what Unix does.



<<plan/plan.rs>>=
    let mut pwbuf = [0; 4096];
    let mut pwd: libc::passwd = unsafe { std::mem::zeroed() };
    let mut result: *mut libc::passwd = std::ptr::null_mut();
@ 

Now, I'm going to admit that I'm a little new to Rust, and this seems a
little looney.  The difference between ``a reference to'' and ``the
address of'' still escapes me.  I suspect Rust wants most programmers to
not worry about it too much, but for interacting with libc, it's kinda
important.  The ``as'' clauses here are for proper memory sizing (I
think), and the underscores are fillers for us to ignore the type; it's
just a mutable pointer.  Apparently, for the second case, it doesn't
even matter that it's a pointer to a pointer.

<<plan/plan.rs>>=
    unsafe {
        libc::getpwnam_r(c_username.as_ptr(),
                         &mut pwd as *mut _,
                         pwbuf.as_mut_ptr(),
                         pwbuf.len() as libc::size_t,
                         &mut result as *mut _)
    };

@ 

The last step is to deliver the result as a string.  We use the
[[to_string_lossy]] function to convert to an internal UTF8
representation, and immediately create an owned copy for the consumer to
use.

<<plan/plan.rs>>=
    match result as u32 {
        0 => Err("User not found."),
        _ => Ok(unsafe {std::ffi::CStr::from_ptr(pwd.pw_dir)}.to_string_lossy().into_owned())
    }
}


@                

\end{document}

